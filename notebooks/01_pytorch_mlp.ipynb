{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import gzip\n",
    "import pickle\n",
    "\n",
    "from typing import Any, Callable, Sequence, Union\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append python path - needed to import text_recognizer\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_mnist(path):\n",
    "    url = \"https://github.com/pytorch/tutorials/raw/master/_static/\"\n",
    "    filename = \"mnist.pkl.gz\"\n",
    "\n",
    "    if not (path / filename).exists():\n",
    "        content = requests.get(url + filename).content\n",
    "        (path / filename).open(\"wb\").write(content)\n",
    "\n",
    "    return path / filename\n",
    "\n",
    "\n",
    "data_path = Path(\"data\") if Path(\"data\").exists() else Path(\"../data\")\n",
    "path = data_path / \"downloaded\" / \"vector-mnist\"\n",
    "path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "datafile = download_mnist(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_mnist(path):\n",
    "    with gzip.open(path, \"rb\") as f:\n",
    "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\")\n",
    "    return x_train, y_train, x_valid, y_valid\n",
    "\n",
    "x_train, y_train, x_valid, y_valid = read_mnist(datafile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_valid, y_valid = map(\n",
    "    torch.tensor, (x_train, y_train, x_valid, y_valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Base Dataset class that simply processes data and targets through optional transforms.\n",
    "\n",
    "    More info: https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset\n",
    "\n",
    "    Attributes:\n",
    "        data: commonly these are torch tensors, numpy arrays, or PIL Images\n",
    "        targets: commonly these are torch tensors or numpy arrays\n",
    "        transform: function that takes a datum and returns the same\n",
    "        target_transform: function that takes a target and returns the same\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data: Union[Sequence, torch.Tensor],\n",
    "        targets: Union[Sequence, torch.Tensor],\n",
    "        transform: Callable = None,\n",
    "        target_transform: Callable = None,\n",
    "    ) -> None:\n",
    "        if len(data) != len(targets):\n",
    "            raise ValueError(\"Data and targets must be of equal length\")\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"Return length of the dataset.\"\"\"\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index: int) -> tuple[Any, Any]:\n",
    "        \"\"\"Return a datum and its target, after processing by transforms.\n",
    "\n",
    "        Args:\n",
    "            index (int): _description_\n",
    "\n",
    "        Returns:\n",
    "            tuple[Any, Any]: (datum, target)\n",
    "        \"\"\"\n",
    "\n",
    "        datum, target = self.data[index], self.targets[index]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            datum = self.transform(datum)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return datum, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 784])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = BaseDataset(x_train, y_train)\n",
    "\n",
    "train_ds.data.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "def push_to_device(tensor):\n",
    "    return tensor.to(device)      \n",
    "\n",
    "    \n",
    "class MNISTDataModule:\n",
    "    url = \"https://github.com/pytorch/tutorials/raw/master/_static/\"\n",
    "    filename = \"mnist.pkl.gz\"\n",
    "    \n",
    "    def __init__(self, dir, bs=32):\n",
    "        self.dir = dir\n",
    "        self.bs = bs\n",
    "        self.path = self.dir / self.filename\n",
    "\n",
    "    def prepare_data(self):\n",
    "        if not (self.path).exists():\n",
    "            content = requests.get(self.url + self.filename).content\n",
    "            self.path.open(\"wb\").write(content)\n",
    "\n",
    "    def setup(self):\n",
    "        with gzip.open(self.path, \"rb\") as f:\n",
    "            ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\")\n",
    "\n",
    "        x_train, y_train, x_valid, y_valid = map(\n",
    "            torch.tensor, (x_train, y_train, x_valid, y_valid)\n",
    "            )\n",
    "        \n",
    "        self.train_ds = BaseDataset(x_train, y_train, transform=push_to_device, target_transform=push_to_device)\n",
    "        self.valid_ds = BaseDataset(x_valid, y_valid, transform=push_to_device, target_transform=push_to_device)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.train_ds, batch_size=self.bs, shuffle=True)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.valid_ds, batch_size=2 * self.bs, shuffle=False)  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model - Basic Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTLogistic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lin = nn.Linear(784, 10) \n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.lin(x)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def configure_optimizer(model: nn.Module) -> optim.Optimizer:\n",
    "    return optim.Adam(model.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(output: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "    return -output[range(target.shape[0]), target].mean()\n",
    "\n",
    "loss_func = cross_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(self: nn.Module, datamodule):\n",
    "    datamodule.prepare_data()\n",
    "    datamodule.setup()\n",
    "\n",
    "    val_dataloader = datamodule.val_dataloader()\n",
    "    \n",
    "    self.eval()\n",
    "    with torch.no_grad():\n",
    "        valid_loss = sum(loss_func(self(xb), yb) for xb, yb in val_dataloader)\n",
    "\n",
    "    print(\"before start of training:\", valid_loss / len(val_dataloader))\n",
    "\n",
    "    opt = configure_optimizer(self)\n",
    "    train_dataloader = datamodule.train_dataloader()\n",
    "    for epoch in range(epochs):\n",
    "        self.train()\n",
    "        for xb, yb in train_dataloader:\n",
    "            pred = self(xb)\n",
    "            loss = loss_func(pred, yb) \n",
    "\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            valid_loss = sum(loss_func(self(xb), yb) for xb, yb in val_dataloader)\n",
    "\n",
    "        # track stats\n",
    "        print(f\"{epoch:7d}/{epochs:7d}: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before start of training: tensor(0.0022)\n",
      "      0/      2: -41.6332\n",
      "      1/      2: -63.2852\n"
     ]
    }
   ],
   "source": [
    "MNISTLogistic.fit = fit\n",
    "\n",
    "model = MNISTLogistic()\n",
    "model.to(device)\n",
    "\n",
    "datamodule = MNISTDataModule(dir=path, bs=32)\n",
    "\n",
    "epochs = 2\n",
    "model.fit(datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_dims': (784,),\n",
       " 'mapping': {0: '0',\n",
       "  1: '1',\n",
       "  2: '2',\n",
       "  3: '3',\n",
       "  4: '4',\n",
       "  5: '5',\n",
       "  6: '6',\n",
       "  7: '7',\n",
       "  8: '8',\n",
       "  9: '9'}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits_to_9 = list(range(10))\n",
    "data_config = {\"input_dims\": (784,), \"mapping\": {digit: str(digit) for digit in digits_to_9}}\n",
    "data_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before start of training: tensor(0.0005)\n",
      "      0/     20: -4569717.0000\n",
      "      1/     20: -29427486.0000\n",
      "      2/     20: -68096296.0000\n",
      "      3/     20: -141538064.0000\n",
      "      4/     20: -277902656.0000\n",
      "      5/     20: -393276928.0000\n",
      "      6/     20: -609995392.0000\n",
      "      7/     20: -693799616.0000\n",
      "      8/     20: -1103068544.0000\n",
      "      9/     20: -1296659200.0000\n",
      "     10/     20: -1626500608.0000\n",
      "     11/     20: -2141411584.0000\n",
      "     12/     20: -2263724032.0000\n",
      "     13/     20: -3361170688.0000\n",
      "     14/     20: -4291849728.0000\n",
      "     15/     20: -5203449856.0000\n",
      "     16/     20: -5750444544.0000\n",
      "     17/     20: -5686204416.0000\n",
      "     18/     20: -7228507136.0000\n",
      "     19/     20: -9068530688.0000\n"
     ]
    }
   ],
   "source": [
    "from text_recognizer.models.mlp import MLP\n",
    "\n",
    "MLP.fit = fit\n",
    "\n",
    "model = MLP(data_config)\n",
    "model.to(device)\n",
    "\n",
    "datamodule = MNISTDataModule(dir=path, bs=32)\n",
    "\n",
    "epochs = 20\n",
    "model.fit(datamodule=datamodule)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text-recognizer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Nov 24 2022, 08:09:04) [Clang 14.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fd46daa45be38af9b17270160ad4c0c0c96408b9434e6adafbdcc4ce6f2bf818"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
